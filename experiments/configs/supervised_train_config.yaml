trajectories_file: /u/spa-d2/grad/mfe261/Projects/Grounding_LLMs_with_online_RL/experiments/data/il_trajs_finalized_images.jsonl
human_goal_file: /u/spa-d2/grad/mfe261/Projects/Grounding_LLMs_with_online_RL/experiments/data/human_goals.json
default_file_path: /u/spa-d2/grad/mfe261/Projects/Grounding_LLMs_with_online_RL/web_agent_site/data/items_shuffle.json
items_human_ins: /u/spa-d2/grad/mfe261/Projects/Grounding_LLMs_with_online_RL/web_agent_site/data/items_human_ins.json
category: all # electronics, fashion, grocery, garden, beauty, all
encoder_max_size: 1024
decoder_max_size: 128
model_name_or_path: google/flan-t5-large
nbr_obs: 2
cache_dir: null
output_dir: /u/spa-d2/grad/mfe261/Projects/Grounding_LLMs_with_online_RL/storage/models
logging_dir: /u/spa-d2/grad/mfe261/Projects/Grounding_LLMs_with_online_RL/storage/logs
run_name: flan_t5_large_2_observations
num_train_epochs: 10
logging_steps: 10
save_strategy: steps
save_steps: 10
evaluation_strategy: steps
eval_steps: 10
gradient_accumulation_steps: 32
eval_accumulation_steps: 8
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
save_total_limit: 1
warmup_steps: 100
weight_decay: 0.01
learning_rate: 0.00002
fp16: false
bf16: false
tf32: false
gradient_checkpointing: false
optim: adafactor
max_train_steps: null
lr_scheduler_type: linear # need some work here
seed: null
resume_from_checkpoint: null
with_tracking: 1
image: 0 # need some work here